{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "732415da01c3a4be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T16:28:47.001019Z",
     "start_time": "2025-08-06T16:28:38.084379Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <9DBE5D5C-AC87-30CA-96DA-F5BC116EDA2B> /opt/homebrew/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <6B8AC17B-04CC-36D0-BD01-780381EFB0CC> /opt/homebrew/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from evaluator import SyntacticCalculator, MorphologicalCalculator, InventoryCalculator, PhonologicalCalculator, FeaturalCalculator, GenericCalculator, LangRankEvaluator, IslandCalculator, GeographicCalculator, HyperbolicCalculator, URIELCalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T17:55:05.571866Z",
     "start_time": "2025-08-06T17:54:57.200884Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = GenericCalculator('data/URIEL_Scriptural.csv')\n",
    "islands = IslandCalculator('data/URIELPlus_Union_SoftImpute.csv')\n",
    "hyperbolic = HyperbolicCalculator()\n",
    "distribution_geo = GeographicCalculator(1)\n",
    "\n",
    "gen = GenericCalculator('data/URIEL_Phylogeny.csv')\n",
    "geo = GenericCalculator('data/URIEL_Geography.csv')\n",
    "typ_file = 'data/URIELPlus_Union.csv' # path to the typological dataset CSV file\n",
    "syn = SyntacticCalculator(typ_file)\n",
    "morph = MorphologicalCalculator(typ_file)\n",
    "inv = InventoryCalculator(typ_file)\n",
    "phon = PhonologicalCalculator(typ_file)\n",
    "feat = FeaturalCalculator(typ_file)\n",
    "\n",
    "gen = URIELCalculator(dist='genetic')\n",
    "geo = URIELCalculator(dist='geographic')\n",
    "syn = URIELCalculator(dist='syntactic')\n",
    "inv = URIELCalculator(dist='inventory')\n",
    "phon = URIELCalculator(dist='phonological')\n",
    "feat = URIELCalculator(dist='featural')\n",
    "\n",
    "evaluator = LangRankEvaluator(\n",
    "    calculators={\n",
    "    'syntactic': syn,\n",
    "    'morphological': morph,\n",
    "    'inventory': inv,\n",
    "    'phonological': phon,\n",
    "    'featural': feat,\n",
    "    'scriptural': script,\n",
    "    'islands': islands,\n",
    "    'new_geographic': distribution_geo, # do not change the name \"new_geographic\"\n",
    "    'geographic': geo,\n",
    "    'hyper_genetic': hyperbolic,\n",
    "    'genetic': gen,\n",
    "    },\n",
    "    iso_map_file='data/code_mapping.csv', # path to the ISO to Glottocode mapping file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f71ed1428876cf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T17:55:05.610774Z",
     "start_time": "2025-08-06T17:55:05.606494Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_ndcg = {\n",
    "    'mt': [],\n",
    "    'dep': [],\n",
    "    'el': [],\n",
    "    'pos': [],\n",
    "    'taxi1500': [],\n",
    "    'xnli': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a490d628dbf7ec7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T18:02:44.046714Z",
     "start_time": "2025-08-06T17:55:05.635180Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2862it [00:00, 3351.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mt NDCG: 33.178795182605505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "870it [00:00, 3530.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: dep NDCG: 73.38781485358571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "477it [00:00, 3385.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: el NDCG: 65.85285889226414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1545it [00:00, 2915.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: pos NDCG: 12.22273337074046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26334it [00:09, 2730.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: taxi1500 NDCG: 27.632791468617157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:00, 4081.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: xnli NDCG: 68.18314778788924\n"
     ]
    }
   ],
   "source": [
    "is_baseline = True # set to True to store the result in baseline_ndcg, which, when passed in the baseline_ndcg_scores parameter in future runs, will give us a p-value\n",
    "features = ['syntactic', 'phonological', 'inventory', 'featural', 'geographic', 'genetic']\n",
    "# features += ['morphological']\n",
    "# features += ['scriptural']\n",
    "# features += ['islands']\n",
    "task_col_name = 'task_lang'\n",
    "transfer_col_name = 'transfer_lang'\n",
    "\n",
    "tasks = {\n",
    "    'mt': ('BLEU', True),\n",
    "    'dep': ('accuracy', True),\n",
    "    'el': ('accuracy', True),\n",
    "    'pos': ('accuracy', True),\n",
    "    'taxi1500': ('f1_score', False),\n",
    "    'xnli': ('accuracy', False),\n",
    "}\n",
    "for task in tasks:\n",
    "    # replace/add distances in the `distance_types` columns of the dataset CSV using the corresponding calculators passed into the evaluator.\n",
    "    evaluator.replace_distances(\n",
    "        dataset_path=f'data/{task}.csv', # path to the task dataset (the one containing columns for task lang, transfer lang, performance)\n",
    "        distance_types=features, # list of distance types to replace in the dataset. these should match the keys of the dict passed into the evaluator.\n",
    "        task_col_name=task_col_name, # name of the task language column in your dataset\n",
    "        transfer_col_name=transfer_col_name, # name of the transfer language column in your dataset\n",
    "        iso_conversion=tasks[task][1] # indicate whether to convert lang codes in your dataset from ISO to Glottocode using the file in self.iso_map_file\n",
    "    )\n",
    "    # run LangRank and evaluate task performance\n",
    "    score = evaluator.evaluate(\n",
    "        dataset_path=f'data/{task}_updated.csv',\n",
    "        features=features, # list of columns in the dataset CSV to use for evaluation\n",
    "        performance_col_name=tasks[task][0], # name of the column in the dataset CSV containing task performance scores\n",
    "        task_col_name=task_col_name,\n",
    "        transfer_col_name=transfer_col_name,\n",
    "        baseline_ndcg_scores=baseline_ndcg[task], # list of baseline NDCG scores for the task\n",
    "    )\n",
    "    if is_baseline:\n",
    "        baseline_ndcg[task] = score[1]\n",
    "        print(f'Task: {task} NDCG: {score[0]}')\n",
    "    else:\n",
    "        print(f'Task: {task} NDCG: {score[0]} (p-value: {score[2]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7053d2fdb533d7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2862it [00:00, 3705.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mt NDCG: 33.38178851427656 (p-value: 0.9365709385245045)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "870it [00:00, 3880.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: dep NDCG: 71.40558968024115 (p-value: 0.38866740383108966)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "477it [00:00, 3899.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: el NDCG: 66.62101145019062 (p-value: 0.9180367500490515)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1545it [00:00, 3432.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: pos NDCG: 12.62306463360568 (p-value: 0.9114903869009069)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26334it [00:08, 3193.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: taxi1500 NDCG: 25.37109601033216 (p-value: 0.010560182011459073)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:00, 3570.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: xnli NDCG: 77.79374158323171 (p-value: 0.004420509288133719)\n"
     ]
    }
   ],
   "source": [
    "is_baseline = False # set to True to store the result in baseline_ndcg, which, when passed in the baseline_ndcg_scores parameter in future runs, will give us a p-value\n",
    "features = ['syntactic', 'phonological', 'inventory', 'featural', 'geographic', 'hyper_genetic']\n",
    "# features += ['morphological']\n",
    "# features += ['scriptural']\n",
    "# features += ['islands']\n",
    "task_col_name = 'task_lang'\n",
    "transfer_col_name = 'transfer_lang'\n",
    "\n",
    "tasks = {\n",
    "    'mt': ('BLEU', True),\n",
    "    'dep': ('accuracy', True),\n",
    "    'el': ('accuracy', True),\n",
    "    'pos': ('accuracy', True),\n",
    "    'taxi1500': ('f1_score', False),\n",
    "    'xnli': ('accuracy', False),\n",
    "}\n",
    "for task in tasks:\n",
    "    # replace/add distances in the `distance_types` columns of the dataset CSV using the corresponding calculators passed into the evaluator.\n",
    "    evaluator.replace_distances(\n",
    "        dataset_path=f'data/{task}.csv', # path to the task dataset (the one containing columns for task lang, transfer lang, performance)\n",
    "        distance_types=features, # list of distance types to replace in the dataset. these should match the keys of the dict passed into the evaluator.\n",
    "        task_col_name=task_col_name, # name of the task language column in your dataset\n",
    "        transfer_col_name=transfer_col_name, # name of the transfer language column in your dataset\n",
    "        iso_conversion=tasks[task][1] # indicate whether to convert lang codes in your dataset from ISO to Glottocode using the file in self.iso_map_file\n",
    "    )\n",
    "    # run LangRank and evaluate task performance\n",
    "    score = evaluator.evaluate(\n",
    "        dataset_path=f'data/{task}_updated.csv',\n",
    "        features=features, # list of columns in the dataset CSV to use for evaluation\n",
    "        performance_col_name=tasks[task][0], # name of the column in the dataset CSV containing task performance scores\n",
    "        task_col_name=task_col_name,\n",
    "        transfer_col_name=transfer_col_name,\n",
    "        baseline_ndcg_scores=baseline_ndcg[task], # list of baseline NDCG scores for the task\n",
    "    )\n",
    "    if is_baseline:\n",
    "        baseline_ndcg[task] = score[1]\n",
    "        print(f'Task: {task} NDCG: {score[0]}')\n",
    "    else:\n",
    "        print(f'Task: {task} NDCG: {score[0]} (p-value: {score[2]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "223f7ed65f79b59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2862it [00:01, 2651.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mt NDCG: 31.740196289406757 (p-value: 0.5638885024610998)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "870it [00:00, 2705.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: dep NDCG: 68.91728165982752 (p-value: 0.09359015961086846)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "477it [00:00, 2629.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: el NDCG: 68.64628904825084 (p-value: 0.6054311655487918)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1545it [00:00, 2438.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: pos NDCG: 20.94201768547877 (p-value: 0.043925454232727104)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26334it [00:10, 2401.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: taxi1500 NDCG: 26.499766850946017 (p-value: 0.1935551140239272)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:00, 2561.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: xnli NDCG: 76.23290388561657 (p-value: 0.018241167973593587)\n"
     ]
    }
   ],
   "source": [
    "is_baseline = False # set to True to store the result in baseline_ndcg, which, when passed in the baseline_ndcg_scores parameter in future runs, will give us a p-value\n",
    "features = ['syntactic', 'phonological', 'inventory', 'featural', 'geographic', 'hyper_genetic', 'scriptural']\n",
    "# features += ['morphological']\n",
    "# features += ['scriptural']\n",
    "# features += ['islands']\n",
    "task_col_name = 'task_lang'\n",
    "transfer_col_name = 'transfer_lang'\n",
    "\n",
    "tasks = {\n",
    "    'mt': ('BLEU', True),\n",
    "    'dep': ('accuracy', True),\n",
    "    'el': ('accuracy', True),\n",
    "    'pos': ('accuracy', True),\n",
    "    'taxi1500': ('f1_score', False),\n",
    "    'xnli': ('accuracy', False),\n",
    "}\n",
    "for task in tasks:\n",
    "    # replace/add distances in the `distance_types` columns of the dataset CSV using the corresponding calculators passed into the evaluator.\n",
    "    evaluator.replace_distances(\n",
    "        dataset_path=f'data/{task}.csv', # path to the task dataset (the one containing columns for task lang, transfer lang, performance)\n",
    "        distance_types=features, # list of distance types to replace in the dataset. these should match the keys of the dict passed into the evaluator.\n",
    "        task_col_name=task_col_name, # name of the task language column in your dataset\n",
    "        transfer_col_name=transfer_col_name, # name of the transfer language column in your dataset\n",
    "        iso_conversion=tasks[task][1] # indicate whether to convert lang codes in your dataset from ISO to Glottocode using the file in self.iso_map_file\n",
    "    )\n",
    "    # run LangRank and evaluate task performance\n",
    "    score = evaluator.evaluate(\n",
    "        dataset_path=f'data/{task}_updated.csv',\n",
    "        features=features, # list of columns in the dataset CSV to use for evaluation\n",
    "        performance_col_name=tasks[task][0], # name of the column in the dataset CSV containing task performance scores\n",
    "        task_col_name=task_col_name,\n",
    "        transfer_col_name=transfer_col_name,\n",
    "        baseline_ndcg_scores=baseline_ndcg[task], # list of baseline NDCG scores for the task\n",
    "    )\n",
    "    if is_baseline:\n",
    "        baseline_ndcg[task] = score[1]\n",
    "        print(f'Task: {task} NDCG: {score[0]}')\n",
    "    else:\n",
    "        print(f'Task: {task} NDCG: {score[0]} (p-value: {score[2]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22de1500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2862it [01:28, 32.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mt NDCG: 34.0392921363971 (p-value: 0.7004604092955105)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "870it [00:26, 32.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: dep NDCG: 69.58263030571608 (p-value: 0.029800696090768474)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "477it [00:14, 32.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: el NDCG: 69.68000081076823 (p-value: 0.6229936850359505)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1545it [00:48, 32.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: pos NDCG: 16.41856616366161 (p-value: 0.14040158523569388)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26334it [14:03, 31.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: taxi1500 NDCG: 25.690537307501465 (p-value: 0.026481385189433958)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:07, 30.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: xnli NDCG: 76.40229462829583 (p-value: 0.03219756482894541)\n"
     ]
    }
   ],
   "source": [
    "is_baseline = False # set to True to store the result in baseline_ndcg, which, when passed in the baseline_ndcg_scores parameter in future runs, will give us a p-value\n",
    "features = ['syntactic', 'phonological', 'inventory', 'featural', 'geographic', 'hyper_genetic', 'islands']\n",
    "# features += ['morphological']\n",
    "# features += ['scriptural']\n",
    "# features += ['islands']\n",
    "task_col_name = 'task_lang'\n",
    "transfer_col_name = 'transfer_lang'\n",
    "\n",
    "tasks = {\n",
    "    'mt': ('BLEU', True),\n",
    "    'dep': ('accuracy', True),\n",
    "    'el': ('accuracy', True),\n",
    "    'pos': ('accuracy', True),\n",
    "    'taxi1500': ('f1_score', False),\n",
    "    'xnli': ('accuracy', False),\n",
    "}\n",
    "for task in tasks:\n",
    "    # replace/add distances in the `distance_types` columns of the dataset CSV using the corresponding calculators passed into the evaluator.\n",
    "    evaluator.replace_distances(\n",
    "        dataset_path=f'data/{task}.csv', # path to the task dataset (the one containing columns for task lang, transfer lang, performance)\n",
    "        distance_types=features, # list of distance types to replace in the dataset. these should match the keys of the dict passed into the evaluator.\n",
    "        task_col_name=task_col_name, # name of the task language column in your dataset\n",
    "        transfer_col_name=transfer_col_name, # name of the transfer language column in your dataset\n",
    "        iso_conversion=tasks[task][1] # indicate whether to convert lang codes in your dataset from ISO to Glottocode using the file in self.iso_map_file\n",
    "    )\n",
    "    # run LangRank and evaluate task performance\n",
    "    score = evaluator.evaluate(\n",
    "        dataset_path=f'data/{task}_updated.csv',\n",
    "        features=features, # list of columns in the dataset CSV to use for evaluation\n",
    "        performance_col_name=tasks[task][0], # name of the column in the dataset CSV containing task performance scores\n",
    "        task_col_name=task_col_name,\n",
    "        transfer_col_name=transfer_col_name,\n",
    "        baseline_ndcg_scores=baseline_ndcg[task], # list of baseline NDCG scores for the task\n",
    "    )\n",
    "    if is_baseline:\n",
    "        baseline_ndcg[task] = score[1]\n",
    "        print(f'Task: {task} NDCG: {score[0]}')\n",
    "    else:\n",
    "        print(f'Task: {task} NDCG: {score[0]} (p-value: {score[2]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d1874b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2862it [01:32, 30.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mt NDCG: 34.565196666658046 (p-value: 0.5730178148567486)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "870it [00:28, 30.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: dep NDCG: 70.08871315278513 (p-value: 0.07066124906034471)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "477it [00:15, 30.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: el NDCG: 59.191612006929375 (p-value: 0.39525602392311443)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1545it [00:48, 31.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: pos NDCG: 15.82543326923029 (p-value: 0.25706319605706035)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26334it [13:59, 31.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: taxi1500 NDCG: 25.70121794375672 (p-value: 0.028436248380615335)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:07, 31.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: xnli NDCG: 77.71306399333756 (p-value: 0.02153656083425652)\n"
     ]
    }
   ],
   "source": [
    "is_baseline = False # set to True to store the result in baseline_ndcg, which, when passed in the baseline_ndcg_scores parameter in future runs, will give us a p-value\n",
    "features = ['syntactic', 'phonological', 'inventory', 'featural', 'geographic', 'hyper_genetic', 'scriptural', 'islands']\n",
    "# features += ['morphological']\n",
    "# features += ['scriptural']\n",
    "# features += ['islands']\n",
    "task_col_name = 'task_lang'\n",
    "transfer_col_name = 'transfer_lang'\n",
    "\n",
    "tasks = {\n",
    "    'mt': ('BLEU', True),\n",
    "    'dep': ('accuracy', True),\n",
    "    'el': ('accuracy', True),\n",
    "    'pos': ('accuracy', True),\n",
    "    'taxi1500': ('f1_score', False),\n",
    "    'xnli': ('accuracy', False),\n",
    "}\n",
    "for task in tasks:\n",
    "    # replace/add distances in the `distance_types` columns of the dataset CSV using the corresponding calculators passed into the evaluator.\n",
    "    evaluator.replace_distances(\n",
    "        dataset_path=f'data/{task}.csv', # path to the task dataset (the one containing columns for task lang, transfer lang, performance)\n",
    "        distance_types=features, # list of distance types to replace in the dataset. these should match the keys of the dict passed into the evaluator.\n",
    "        task_col_name=task_col_name, # name of the task language column in your dataset\n",
    "        transfer_col_name=transfer_col_name, # name of the transfer language column in your dataset\n",
    "        iso_conversion=tasks[task][1] # indicate whether to convert lang codes in your dataset from ISO to Glottocode using the file in self.iso_map_file\n",
    "    )\n",
    "    # run LangRank and evaluate task performance\n",
    "    score = evaluator.evaluate(\n",
    "        dataset_path=f'data/{task}_updated.csv',\n",
    "        features=features, # list of columns in the dataset CSV to use for evaluation\n",
    "        performance_col_name=tasks[task][0], # name of the column in the dataset CSV containing task performance scores\n",
    "        task_col_name=task_col_name,\n",
    "        transfer_col_name=transfer_col_name,\n",
    "        baseline_ndcg_scores=baseline_ndcg[task], # list of baseline NDCG scores for the task\n",
    "    )\n",
    "    if is_baseline:\n",
    "        baseline_ndcg[task] = score[1]\n",
    "        print(f'Task: {task} NDCG: {score[0]}')\n",
    "    else:\n",
    "        print(f'Task: {task} NDCG: {score[0]} (p-value: {score[2]})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
