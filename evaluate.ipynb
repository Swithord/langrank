{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "732415da01c3a4be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T16:28:47.001019Z",
     "start_time": "2025-08-06T16:28:38.084379Z"
    }
   },
   "outputs": [],
   "source": [
    "from evaluator import SyntacticCalculator, MorphologicalCalculator, InventoryCalculator, PhonologicalCalculator, FeaturalCalculator, GenericCalculator, LangRankEvaluator, IslandCalculator, GeographicCalculator, HyperbolicCalculator, URIELCalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T17:55:05.571866Z",
     "start_time": "2025-08-06T17:54:57.200884Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "script = GenericCalculator('data/URIEL_Scriptural.csv')\n",
    "islands = IslandCalculator('data/URIELPlus_Union_SoftImpute.csv')\n",
    "hyperbolic = HyperbolicCalculator()\n",
    "distribution_geo = GeographicCalculator(1)\n",
    "\n",
    "gen = GenericCalculator('data/URIEL_Phylogeny.csv')\n",
    "geo = GenericCalculator('data/URIEL_Geography.csv')\n",
    "typ_file = 'data/URIELPlus_Union.csv' # path to the typological dataset CSV file\n",
    "syn = SyntacticCalculator(typ_file)\n",
    "morph = MorphologicalCalculator(typ_file)\n",
    "inv = InventoryCalculator(typ_file)\n",
    "phon = PhonologicalCalculator(typ_file)\n",
    "feat = FeaturalCalculator(typ_file)\n",
    "\n",
    "# gen = URIELCalculator(dist='genetic')\n",
    "# geo = URIELCalculator(dist='geographic')\n",
    "# syn = URIELCalculator(dist='syntactic')\n",
    "# inv = URIELCalculator(dist='inventory')\n",
    "# phon = URIELCalculator(dist='phonological')\n",
    "# feat = URIELCalculator(dist='featural')\n",
    "\n",
    "evaluator = LangRankEvaluator(\n",
    "    calculators={\n",
    "    'syntactic': syn,\n",
    "    'morphological': morph,\n",
    "    'inventory': inv,\n",
    "    'phonological': phon,\n",
    "    'featural': feat,\n",
    "    'scriptural': script,\n",
    "    'islands': islands,\n",
    "    'new_geographic': distribution_geo, # do not change the name \"new_geographic\"\n",
    "    'geographic': geo,\n",
    "    'hyper_genetic': hyperbolic,\n",
    "    'genetic': gen,\n",
    "    },\n",
    "    iso_map_file='data/code_mapping.csv', # path to the ISO to Glottocode mapping file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f71ed1428876cf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T17:55:05.610774Z",
     "start_time": "2025-08-06T17:55:05.606494Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_ndcg = {\n",
    "    'mt': [],\n",
    "    'dep': [],\n",
    "    'el': [],\n",
    "    'pos': [],\n",
    "    'taxi1500': [],\n",
    "    'xnli': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a490d628dbf7ec7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-06T18:02:44.046714Z",
     "start_time": "2025-08-06T17:55:05.635180Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2862it [00:07, 398.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mt NDCG: 30.923161574748253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "870it [00:01, 446.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: dep NDCG: 72.80298281709919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "477it [00:01, 448.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: el NDCG: 65.83247072894687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1545it [00:03, 453.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: pos NDCG: 22.399150587343524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26334it [00:58, 449.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: taxi1500 NDCG: 22.552406960492387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:00, 374.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: xnli NDCG: 70.64718813913777\n"
     ]
    }
   ],
   "source": [
    "is_baseline = True # set to True to store the result in baseline_ndcg, which, when passed in the baseline_ndcg_scores parameter in future runs, will give us a p-value\n",
    "features = ['syntactic', 'phonological', 'morphological', 'inventory', 'featural', 'geographic', 'genetic']\n",
    "# features += ['morphological']\n",
    "# features += ['scriptural']\n",
    "# features += ['islands']\n",
    "task_col_name = 'task_lang'\n",
    "transfer_col_name = 'transfer_lang'\n",
    "\n",
    "tasks = {\n",
    "    'mt': ('BLEU', True),\n",
    "    'dep': ('accuracy', True),\n",
    "    'el': ('accuracy', True),\n",
    "    'pos': ('accuracy', True),\n",
    "    'taxi1500': ('f1_score', False),\n",
    "    'xnli': ('accuracy', False),\n",
    "}\n",
    "for task in tasks:\n",
    "    # replace/add distances in the `distance_types` columns of the dataset CSV using the corresponding calculators passed into the evaluator.\n",
    "    evaluator.replace_distances(\n",
    "        dataset_path=f'data/{task}.csv', # path to the task dataset (the one containing columns for task lang, transfer lang, performance)\n",
    "        distance_types=features, # list of distance types to replace in the dataset. these should match the keys of the dict passed into the evaluator.\n",
    "        task_col_name=task_col_name, # name of the task language column in your dataset\n",
    "        transfer_col_name=transfer_col_name, # name of the transfer language column in your dataset\n",
    "        iso_conversion=tasks[task][1] # indicate whether to convert lang codes in your dataset from ISO to Glottocode using the file in self.iso_map_file\n",
    "    )\n",
    "    # run LangRank and evaluate task performance\n",
    "    score = evaluator.evaluate(\n",
    "        dataset_path=f'data/{task}_updated.csv',\n",
    "        features=features, # list of columns in the dataset CSV to use for evaluation\n",
    "        performance_col_name=tasks[task][0], # name of the column in the dataset CSV containing task performance scores\n",
    "        task_col_name=task_col_name,\n",
    "        transfer_col_name=transfer_col_name,\n",
    "        baseline_ndcg_scores=baseline_ndcg[task], # list of baseline NDCG scores for the task\n",
    "    )\n",
    "    if is_baseline:\n",
    "        baseline_ndcg[task] = score[1]\n",
    "        print(f'Task: {task} NDCG: {score[0]}')\n",
    "    else:\n",
    "        print(f'Task: {task} NDCG: {score[0]} (p-value: {score[2]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7053d2fdb533d7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2862it [00:03, 860.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mt NDCG: 31.58215211231783 (p-value: 0.8122635044499287)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "870it [00:00, 900.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: dep NDCG: 73.5350273080687 (p-value: 0.5970921265773466)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "477it [00:00, 910.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: el NDCG: 66.18629125674565 (p-value: 0.9102454953711276)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1545it [00:01, 979.28it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: pos NDCG: 20.905366257292794 (p-value: 0.6960849634781787)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26334it [00:26, 983.36it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: taxi1500 NDCG: 22.315357253085494 (p-value: 0.7740319559249291)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:00, 810.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: xnli NDCG: 68.98156616295549 (p-value: 0.5390611845403848)\n"
     ]
    }
   ],
   "source": [
    "is_baseline = False # set to True to store the result in baseline_ndcg, which, when passed in the baseline_ndcg_scores parameter in future runs, will give us a p-value\n",
    "features = ['syntactic', 'phonological', 'morphological', 'inventory', 'featural', 'geographic', 'hyper_genetic']\n",
    "# features += ['morphological']\n",
    "# features += ['scriptural']\n",
    "# features += ['islands']\n",
    "task_col_name = 'task_lang'\n",
    "transfer_col_name = 'transfer_lang'\n",
    "\n",
    "tasks = {\n",
    "    'mt': ('BLEU', True),\n",
    "    'dep': ('accuracy', True),\n",
    "    'el': ('accuracy', True),\n",
    "    'pos': ('accuracy', True),\n",
    "    'taxi1500': ('f1_score', False),\n",
    "    'xnli': ('accuracy', False),\n",
    "}\n",
    "for task in tasks:\n",
    "    # replace/add distances in the `distance_types` columns of the dataset CSV using the corresponding calculators passed into the evaluator.\n",
    "    evaluator.replace_distances(\n",
    "        dataset_path=f'data/{task}.csv', # path to the task dataset (the one containing columns for task lang, transfer lang, performance)\n",
    "        distance_types=features, # list of distance types to replace in the dataset. these should match the keys of the dict passed into the evaluator.\n",
    "        task_col_name=task_col_name, # name of the task language column in your dataset\n",
    "        transfer_col_name=transfer_col_name, # name of the transfer language column in your dataset\n",
    "        iso_conversion=tasks[task][1] # indicate whether to convert lang codes in your dataset from ISO to Glottocode using the file in self.iso_map_file\n",
    "    )\n",
    "    # run LangRank and evaluate task performance\n",
    "    score = evaluator.evaluate(\n",
    "        dataset_path=f'data/{task}_updated.csv',\n",
    "        features=features, # list of columns in the dataset CSV to use for evaluation\n",
    "        performance_col_name=tasks[task][0], # name of the column in the dataset CSV containing task performance scores\n",
    "        task_col_name=task_col_name,\n",
    "        transfer_col_name=transfer_col_name,\n",
    "        baseline_ndcg_scores=baseline_ndcg[task], # list of baseline NDCG scores for the task\n",
    "    )\n",
    "    if is_baseline:\n",
    "        baseline_ndcg[task] = score[1]\n",
    "        print(f'Task: {task} NDCG: {score[0]}')\n",
    "    else:\n",
    "        print(f'Task: {task} NDCG: {score[0]} (p-value: {score[2]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "223f7ed65f79b59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2862it [00:03, 887.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mt NDCG: 32.27709291756569 (p-value: 0.5896618966405693)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "870it [00:00, 916.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: dep NDCG: 74.38198102146512 (p-value: 0.31621080875963997)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "477it [00:00, 875.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: el NDCG: 67.49213860215669 (p-value: 0.6294661525874257)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1545it [00:01, 927.64it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: pos NDCG: 20.149153162076423 (p-value: 0.6580312723782811)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26334it [00:28, 932.48it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: taxi1500 NDCG: 25.02443518153058 (p-value: 0.005541663555145187)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:00, 735.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: xnli NDCG: 71.85703002656574 (p-value: 0.5822683274578472)\n"
     ]
    }
   ],
   "source": [
    "is_baseline = False # set to True to store the result in baseline_ndcg, which, when passed in the baseline_ndcg_scores parameter in future runs, will give us a p-value\n",
    "features = ['syntactic', 'phonological', 'morphological', 'inventory', 'featural', 'geographic', 'hyper_genetic', 'scriptural']\n",
    "# features += ['morphological']\n",
    "# features += ['scriptural']\n",
    "# features += ['islands']\n",
    "task_col_name = 'task_lang'\n",
    "transfer_col_name = 'transfer_lang'\n",
    "\n",
    "tasks = {\n",
    "    'mt': ('BLEU', True),\n",
    "    'dep': ('accuracy', True),\n",
    "    'el': ('accuracy', True),\n",
    "    'pos': ('accuracy', True),\n",
    "    'taxi1500': ('f1_score', False),\n",
    "    'xnli': ('accuracy', False),\n",
    "}\n",
    "for task in tasks:\n",
    "    # replace/add distances in the `distance_types` columns of the dataset CSV using the corresponding calculators passed into the evaluator.\n",
    "    evaluator.replace_distances(\n",
    "        dataset_path=f'data/{task}.csv', # path to the task dataset (the one containing columns for task lang, transfer lang, performance)\n",
    "        distance_types=features, # list of distance types to replace in the dataset. these should match the keys of the dict passed into the evaluator.\n",
    "        task_col_name=task_col_name, # name of the task language column in your dataset\n",
    "        transfer_col_name=transfer_col_name, # name of the transfer language column in your dataset\n",
    "        iso_conversion=tasks[task][1] # indicate whether to convert lang codes in your dataset from ISO to Glottocode using the file in self.iso_map_file\n",
    "    )\n",
    "    # run LangRank and evaluate task performance\n",
    "    score = evaluator.evaluate(\n",
    "        dataset_path=f'data/{task}_updated.csv',\n",
    "        features=features, # list of columns in the dataset CSV to use for evaluation\n",
    "        performance_col_name=tasks[task][0], # name of the column in the dataset CSV containing task performance scores\n",
    "        task_col_name=task_col_name,\n",
    "        transfer_col_name=transfer_col_name,\n",
    "        baseline_ndcg_scores=baseline_ndcg[task], # list of baseline NDCG scores for the task\n",
    "    )\n",
    "    if is_baseline:\n",
    "        baseline_ndcg[task] = score[1]\n",
    "        print(f'Task: {task} NDCG: {score[0]}')\n",
    "    else:\n",
    "        print(f'Task: {task} NDCG: {score[0]} (p-value: {score[2]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22de1500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2862it [01:34, 30.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mt NDCG: 35.702598325925585 (p-value: 0.1081056964208485)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "870it [00:28, 30.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: dep NDCG: 73.15799640873186 (p-value: 0.7379781498630487)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "477it [00:15, 30.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: el NDCG: 67.83822533254497 (p-value: 0.5758692192568735)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1545it [00:49, 30.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: pos NDCG: 20.99319835054712 (p-value: 0.7719194572627636)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26334it [14:14, 30.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: taxi1500 NDCG: 22.69183929130635 (p-value: 0.8732676337890489)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:07, 28.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: xnli NDCG: 80.18128310652367 (p-value: 0.007146437015958149)\n"
     ]
    }
   ],
   "source": [
    "is_baseline = False # set to True to store the result in baseline_ndcg, which, when passed in the baseline_ndcg_scores parameter in future runs, will give us a p-value\n",
    "features = ['syntactic', 'phonological', 'morphological', 'inventory', 'featural', 'geographic', 'hyper_genetic', 'islands']\n",
    "# features += ['morphological']\n",
    "# features += ['scriptural']\n",
    "# features += ['islands']\n",
    "task_col_name = 'task_lang'\n",
    "transfer_col_name = 'transfer_lang'\n",
    "\n",
    "tasks = {\n",
    "    'mt': ('BLEU', True),\n",
    "    'dep': ('accuracy', True),\n",
    "    'el': ('accuracy', True),\n",
    "    'pos': ('accuracy', True),\n",
    "    'taxi1500': ('f1_score', False),\n",
    "    'xnli': ('accuracy', False),\n",
    "}\n",
    "for task in tasks:\n",
    "    # replace/add distances in the `distance_types` columns of the dataset CSV using the corresponding calculators passed into the evaluator.\n",
    "    evaluator.replace_distances(\n",
    "        dataset_path=f'data/{task}.csv', # path to the task dataset (the one containing columns for task lang, transfer lang, performance)\n",
    "        distance_types=features, # list of distance types to replace in the dataset. these should match the keys of the dict passed into the evaluator.\n",
    "        task_col_name=task_col_name, # name of the task language column in your dataset\n",
    "        transfer_col_name=transfer_col_name, # name of the transfer language column in your dataset\n",
    "        iso_conversion=tasks[task][1] # indicate whether to convert lang codes in your dataset from ISO to Glottocode using the file in self.iso_map_file\n",
    "    )\n",
    "    # run LangRank and evaluate task performance\n",
    "    score = evaluator.evaluate(\n",
    "        dataset_path=f'data/{task}_updated.csv',\n",
    "        features=features, # list of columns in the dataset CSV to use for evaluation\n",
    "        performance_col_name=tasks[task][0], # name of the column in the dataset CSV containing task performance scores\n",
    "        task_col_name=task_col_name,\n",
    "        transfer_col_name=transfer_col_name,\n",
    "        baseline_ndcg_scores=baseline_ndcg[task], # list of baseline NDCG scores for the task\n",
    "    )\n",
    "    if is_baseline:\n",
    "        baseline_ndcg[task] = score[1]\n",
    "        print(f'Task: {task} NDCG: {score[0]}')\n",
    "    else:\n",
    "        print(f'Task: {task} NDCG: {score[0]} (p-value: {score[2]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d1874b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2862it [01:36, 29.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: mt NDCG: 32.56337413068959 (p-value: 0.5368681166575215)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "870it [00:28, 30.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: dep NDCG: 73.56733054012477 (p-value: 0.6704307962942986)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "477it [00:15, 30.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: el NDCG: 70.45301410005519 (p-value: 0.2886382710503333)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1545it [00:52, 29.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: pos NDCG: 22.351564033415556 (p-value: 0.9926477761244141)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26334it [14:31, 30.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: taxi1500 NDCG: 24.281940463792363 (p-value: 0.053371336298922205)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:07, 30.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: xnli NDCG: 77.37428250797899 (p-value: 0.03886305604810488)\n"
     ]
    }
   ],
   "source": [
    "is_baseline = False # set to True to store the result in baseline_ndcg, which, when passed in the baseline_ndcg_scores parameter in future runs, will give us a p-value\n",
    "features = ['syntactic', 'phonological', 'morphological', 'inventory', 'featural', 'geographic', 'hyper_genetic', 'scriptural', 'islands']\n",
    "# features += ['morphological']\n",
    "# features += ['scriptural']\n",
    "# features += ['islands']\n",
    "task_col_name = 'task_lang'\n",
    "transfer_col_name = 'transfer_lang'\n",
    "\n",
    "tasks = {\n",
    "    'mt': ('BLEU', True),\n",
    "    'dep': ('accuracy', True),\n",
    "    'el': ('accuracy', True),\n",
    "    'pos': ('accuracy', True),\n",
    "    'taxi1500': ('f1_score', False),\n",
    "    'xnli': ('accuracy', False),\n",
    "}\n",
    "for task in tasks:\n",
    "    # replace/add distances in the `distance_types` columns of the dataset CSV using the corresponding calculators passed into the evaluator.\n",
    "    evaluator.replace_distances(\n",
    "        dataset_path=f'data/{task}.csv', # path to the task dataset (the one containing columns for task lang, transfer lang, performance)\n",
    "        distance_types=features, # list of distance types to replace in the dataset. these should match the keys of the dict passed into the evaluator.\n",
    "        task_col_name=task_col_name, # name of the task language column in your dataset\n",
    "        transfer_col_name=transfer_col_name, # name of the transfer language column in your dataset\n",
    "        iso_conversion=tasks[task][1] # indicate whether to convert lang codes in your dataset from ISO to Glottocode using the file in self.iso_map_file\n",
    "    )\n",
    "    # run LangRank and evaluate task performance\n",
    "    score = evaluator.evaluate(\n",
    "        dataset_path=f'data/{task}_updated.csv',\n",
    "        features=features, # list of columns in the dataset CSV to use for evaluation\n",
    "        performance_col_name=tasks[task][0], # name of the column in the dataset CSV containing task performance scores\n",
    "        task_col_name=task_col_name,\n",
    "        transfer_col_name=transfer_col_name,\n",
    "        baseline_ndcg_scores=baseline_ndcg[task], # list of baseline NDCG scores for the task\n",
    "    )\n",
    "    if is_baseline:\n",
    "        baseline_ndcg[task] = score[1]\n",
    "        print(f'Task: {task} NDCG: {score[0]}')\n",
    "    else:\n",
    "        print(f'Task: {task} NDCG: {score[0]} (p-value: {score[2]})')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
