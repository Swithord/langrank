{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-05T03:55:06.174080Z",
     "start_time": "2025-08-05T03:55:02.486701Z"
    }
   },
   "source": [
    "from evaluator import SyntacticCalculator, MorphologicalCalculator, InventoryCalculator, PhonologicalCalculator, FeaturalCalculator, GenericCalculator, LangRankEvaluator, IslandCalculator\n",
    "script = GenericCalculator('data/URIEL_Scriptural.csv')\n",
    "islands = IslandCalculator('data/URIELPlus_Union_SoftImpute.csv')\n",
    "geo = GenericCalculator('data/URIEL_Geography.csv')\n",
    "gen = GenericCalculator('data/URIEL_Phylogeny.csv')\n",
    "typ_file = 'data/URIELPlus_Union.csv' # path to the typological dataset CSV file\n",
    "syn = SyntacticCalculator(typ_file)\n",
    "morph = MorphologicalCalculator(typ_file)\n",
    "inv = InventoryCalculator(typ_file)\n",
    "phon = PhonologicalCalculator(typ_file)\n",
    "feat = FeaturalCalculator(typ_file)\n",
    "evaluator = LangRankEvaluator(\n",
    "    calculators={\n",
    "    'syntactic': syn,\n",
    "    'morphological': morph,\n",
    "    'inventory': inv,\n",
    "    'phonological': phon,\n",
    "    'featural': feat,\n",
    "    'scriptural': script,\n",
    "    'islands': islands,\n",
    "    'geographic': geo,\n",
    "    'genetic': gen,\n",
    "    },\n",
    "    iso_map_file='data/code_mapping.csv', # path to the ISO to Glottocode mapping file\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "baseline_ndcg = {\n",
    "    'mt': [],\n",
    "    'dep': [],\n",
    "    'el': [],\n",
    "    'pos': [],\n",
    "    'taxi1500': [],\n",
    "    'xnli': []\n",
    "}"
   ],
   "id": "4f71ed1428876cf8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T04:51:48.375158Z",
     "start_time": "2025-08-05T04:51:42.936516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "is_baseline = True\n",
    "features = ['syntactic', 'phonological', 'inventory', 'featural', 'geographic', 'genetic']\n",
    "# features += ['morphological']\n",
    "# features += ['scriptural']\n",
    "# features += ['islands']\n",
    "task_col_name = 'task_lang'\n",
    "transfer_col_name = 'transfer_lang'\n",
    "\n",
    "tasks = {\n",
    "    'mt': ('BLEU', True),\n",
    "    'dep': ('accuracy', True),\n",
    "    'el': ('accuracy', True),\n",
    "    'pos': ('accuracy', True),\n",
    "    # 'taxi1500': ('f1_score', False),\n",
    "    'xnli': ('accuracy', False),\n",
    "}\n",
    "for task in tasks:\n",
    "    # replace/add distances in the `distance_types` columns of the dataset CSV using the corresponding calculators passed into the evaluator.\n",
    "    evaluator.replace_distances(\n",
    "        dataset_path=f'data/{task}.csv', # path to the task dataset (the one containing columns for task lang, transfer lang, performance)\n",
    "        distance_types=features, # list of distance types to replace in the dataset. these should match the keys of the dict passed into the evaluator.\n",
    "        task_col_name=task_col_name, # name of the task language column in your dataset\n",
    "        transfer_col_name=transfer_col_name, # name of the transfer language column in your dataset\n",
    "        iso_conversion=tasks[task][1] # indicate whether to convert lang codes in your dataset from ISO to Glottocode using the file in self.iso_map_file\n",
    "    )\n",
    "    # run LangRank and evaluate task performance\n",
    "    score = evaluator.evaluate(\n",
    "        dataset_path=f'data/{task}_updated.csv',\n",
    "        features=features, # list of columns in the dataset CSV to use for evaluation\n",
    "        performance_col_name=tasks[task][0], # name of the column in the dataset CSV containing task performance scores\n",
    "        task_col_name=task_col_name,\n",
    "        transfer_col_name=transfer_col_name,\n",
    "        baseline_ndcg_scores=baseline_ndcg[task], # list of baseline NDCG scores for the task\n",
    "    )\n",
    "    if is_baseline:\n",
    "        baseline_ndcg[task].append(score[1])\n",
    "        print(f'Task: {task} NDCG: {score[0]}')\n",
    "    else:\n",
    "        print(f'Task: {task} NDCG: {score[0]} (p-value: {score[2]})')"
   ],
   "id": "a490d628dbf7ec7a",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 19\u001B[39m\n\u001B[32m      9\u001B[39m tasks = {\n\u001B[32m     10\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mmt\u001B[39m\u001B[33m'\u001B[39m: (\u001B[33m'\u001B[39m\u001B[33mBLEU\u001B[39m\u001B[33m'\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[32m     11\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mdep\u001B[39m\u001B[33m'\u001B[39m: (\u001B[33m'\u001B[39m\u001B[33maccuracy\u001B[39m\u001B[33m'\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[32m   (...)\u001B[39m\u001B[32m     15\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mxnli\u001B[39m\u001B[33m'\u001B[39m: (\u001B[33m'\u001B[39m\u001B[33maccuracy\u001B[39m\u001B[33m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[32m     16\u001B[39m }\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m task \u001B[38;5;129;01min\u001B[39;00m tasks:\n\u001B[32m     18\u001B[39m     \u001B[38;5;66;03m# replace/add distances in the `distance_types` columns of the dataset CSV using the corresponding calculators passed into the evaluator.\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m     \u001B[43mevaluator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mreplace_distances\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     20\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdataset_path\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mdata/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mtask\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m.csv\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# path to the task dataset (the one containing columns for task lang, transfer lang, performance)\u001B[39;49;00m\n\u001B[32m     21\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdistance_types\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# list of distance types to replace in the dataset. these should match the keys of the dict passed into the evaluator.\u001B[39;49;00m\n\u001B[32m     22\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtask_col_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtask_col_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# name of the task language column in your dataset\u001B[39;49;00m\n\u001B[32m     23\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtransfer_col_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtransfer_col_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# name of the transfer language column in your dataset\u001B[39;49;00m\n\u001B[32m     24\u001B[39m \u001B[43m        \u001B[49m\u001B[43miso_conversion\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtask\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# indicate whether to convert lang codes in your dataset from ISO to Glottocode using the file in self.iso_map_file\u001B[39;49;00m\n\u001B[32m     25\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     26\u001B[39m     \u001B[38;5;66;03m# run LangRank and evaluate task performance\u001B[39;00m\n\u001B[32m     27\u001B[39m     score = evaluator.evaluate(\n\u001B[32m     28\u001B[39m         dataset_path=\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[33mdata/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtask\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_updated.csv\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m     29\u001B[39m         features=features, \u001B[38;5;66;03m# list of columns in the dataset CSV to use for evaluation\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     33\u001B[39m         baseline_ndcg_scores=baseline_ndcg[task], \u001B[38;5;66;03m# list of baseline NDCG scores for the task\u001B[39;00m\n\u001B[32m     34\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/lr/evaluator.py:187\u001B[39m, in \u001B[36mLangRankEvaluator.replace_distances\u001B[39m\u001B[34m(self, dataset_path, distance_types, task_col_name, transfer_col_name, iso_conversion)\u001B[39m\n\u001B[32m    185\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m distance_type \u001B[38;5;129;01min\u001B[39;00m distance_types:\n\u001B[32m    186\u001B[39m         distance = \u001B[38;5;28mself\u001B[39m.calculators[distance_type].calculate_distance(target_lang, transfer_lang)\n\u001B[32m--> \u001B[39m\u001B[32m187\u001B[39m         \u001B[43mdf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mat\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdistance_type\u001B[49m\u001B[43m]\u001B[49m = distance\n\u001B[32m    188\u001B[39m path_split = dataset_path.split(\u001B[33m'\u001B[39m\u001B[33m.\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    189\u001B[39m df.to_csv(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m'\u001B[39m.join(path_split[:-\u001B[32m1\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m_updated.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_split[-\u001B[32m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m, index=\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/URIELPlus/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:2586\u001B[39m, in \u001B[36m_AtIndexer.__setitem__\u001B[39m\u001B[34m(self, key, value)\u001B[39m\n\u001B[32m   2583\u001B[39m     \u001B[38;5;28mself\u001B[39m.obj.loc[key] = value\n\u001B[32m   2584\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m2586\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__setitem__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/URIELPlus/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:2542\u001B[39m, in \u001B[36m_ScalarAccessIndexer.__setitem__\u001B[39m\u001B[34m(self, key, value)\u001B[39m\n\u001B[32m   2539\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(key) != \u001B[38;5;28mself\u001B[39m.ndim:\n\u001B[32m   2540\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33m\"\u001B[39m\u001B[33mNot enough indexers for scalar access (setting)!\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m2542\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_set_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m=\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtakeable\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_takeable\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/URIELPlus/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4563\u001B[39m, in \u001B[36mDataFrame._set_value\u001B[39m\u001B[34m(self, index, col, value, takeable)\u001B[39m\n\u001B[32m   4561\u001B[39m         icol = \u001B[38;5;28mself\u001B[39m.columns.get_loc(col)\n\u001B[32m   4562\u001B[39m         iindex = \u001B[38;5;28mself\u001B[39m.index.get_loc(index)\n\u001B[32m-> \u001B[39m\u001B[32m4563\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_mgr\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcolumn_setitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43micol\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace_only\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m   4564\u001B[39m     \u001B[38;5;28mself\u001B[39m._clear_item_cache()\n\u001B[32m   4566\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mKeyError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m, LossySetitemError):\n\u001B[32m   4567\u001B[39m     \u001B[38;5;66;03m# get_loc might raise a KeyError for missing labels (falling back\u001B[39;00m\n\u001B[32m   4568\u001B[39m     \u001B[38;5;66;03m#  to (i)loc will do expansion of the index)\u001B[39;00m\n\u001B[32m   4569\u001B[39m     \u001B[38;5;66;03m# column_setitem will do validation that may raise TypeError,\u001B[39;00m\n\u001B[32m   4570\u001B[39m     \u001B[38;5;66;03m#  ValueError, or LossySetitemError\u001B[39;00m\n\u001B[32m   4571\u001B[39m     \u001B[38;5;66;03m# set using a non-recursive method & reset the cache\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/URIELPlus/.venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:1335\u001B[39m, in \u001B[36mBlockManager.column_setitem\u001B[39m\u001B[34m(self, loc, idx, value, inplace_only)\u001B[39m\n\u001B[32m   1333\u001B[39m col_mgr = \u001B[38;5;28mself\u001B[39m.iget(loc, track_ref=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m   1334\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m inplace_only:\n\u001B[32m-> \u001B[39m\u001B[32m1335\u001B[39m     \u001B[43mcol_mgr\u001B[49m\u001B[43m.\u001B[49m\u001B[43msetitem_inplace\u001B[49m\u001B[43m(\u001B[49m\u001B[43midx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1336\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1337\u001B[39m     new_mgr = col_mgr.setitem((idx,), value)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/URIELPlus/.venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:2044\u001B[39m, in \u001B[36mSingleBlockManager.setitem_inplace\u001B[39m\u001B[34m(self, indexer, value, warn)\u001B[39m\n\u001B[32m   2037\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m warn_cow \u001B[38;5;129;01mand\u001B[39;00m warn:\n\u001B[32m   2038\u001B[39m         warnings.warn(\n\u001B[32m   2039\u001B[39m             COW_WARNING_SETITEM_MSG,\n\u001B[32m   2040\u001B[39m             \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[32m   2041\u001B[39m             stacklevel=find_stack_level(),\n\u001B[32m   2042\u001B[39m         )\n\u001B[32m-> \u001B[39m\u001B[32m2044\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43msetitem_inplace\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/URIELPlus/.venv/lib/python3.11/site-packages/pandas/core/internals/base.py:357\u001B[39m, in \u001B[36mSingleDataManager.setitem_inplace\u001B[39m\u001B[34m(self, indexer, value, warn)\u001B[39m\n\u001B[32m    353\u001B[39m \u001B[38;5;66;03m# EAs will do this validation in their own __setitem__ methods.\u001B[39;00m\n\u001B[32m    354\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arr, np.ndarray):\n\u001B[32m    355\u001B[39m     \u001B[38;5;66;03m# Note: checking for ndarray instead of np.dtype means we exclude\u001B[39;00m\n\u001B[32m    356\u001B[39m     \u001B[38;5;66;03m#  dt64/td64, which do their own validation.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m357\u001B[39m     value = \u001B[43mnp_can_hold_element\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    359\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, np.ndarray) \u001B[38;5;129;01mand\u001B[39;00m value.ndim == \u001B[32m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(value) == \u001B[32m1\u001B[39m:\n\u001B[32m    360\u001B[39m     \u001B[38;5;66;03m# NumPy 1.25 deprecation: https://github.com/numpy/numpy/pull/10615\u001B[39;00m\n\u001B[32m    361\u001B[39m     value = value[\u001B[32m0\u001B[39m, ...]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/URIELPlus/.venv/lib/python3.11/site-packages/pandas/core/dtypes/cast.py:1859\u001B[39m, in \u001B[36mnp_can_hold_element\u001B[39m\u001B[34m(dtype, element)\u001B[39m\n\u001B[32m   1856\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m LossySetitemError\n\u001B[32m   1858\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m dtype.kind == \u001B[33m\"\u001B[39m\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m1859\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mlib\u001B[49m\u001B[43m.\u001B[49m\u001B[43mis_integer\u001B[49m\u001B[43m(\u001B[49m\u001B[43melement\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mor\u001B[39;00m lib.is_float(element):\n\u001B[32m   1860\u001B[39m         casted = dtype.type(element)\n\u001B[32m   1861\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m np.isnan(casted) \u001B[38;5;129;01mor\u001B[39;00m casted == element:\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-05T03:35:59.471416Z",
     "start_time": "2025-08-05T03:35:59.469393Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7053d2fdb533d7d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "223f7ed65f79b59a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
